---
title: "Removal models"
author: "Roy Martin"
date: "`r Sys.Date()`"
output:
  github_document:
    toc: true
    toc_depth: 5
    number_sections: true
    keep_html: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, echo = FALSE, warning=FALSE, message=FALSE}
library(ggpubr)
library(ggplot2)
library(ggExtra)
library(gridExtra)
library(dplyr)
library(tidyverse)
library(tidyr)
library(bayesplot)
library(tidybayes)
library(rstan)
library(SBC) # install at: devtools::install_github("hyunjimoon/SBC")

options(mc.cores = parallel::detectCores(logical = FALSE))
options( max.print = 1000 )

# stat: skew 
skew <- function(x) {
  xdev <- x - mean(x)
  n <- length(x)
  r <- sum(xdev^3) / sum(xdev^2)^1.5
  return(r * sqrt(n) * (1 - 1/n)^1.5)
}
```



```
model {
pMean ~ dunif(0,1)
etaMean <- log(pMean/(1-pMean))
b ~ dnorm(0,0.001)
etaSigma ~ dunif(0,10)
etaTau <- 1/(etaSigma * etaSigma)
bSigma ~ dunif(0,10)
bTau <- 1/(bSigma * bSigma)
epsSigma ~ dunif(0,10)
epsTau <- 1/(epsSigma * epsSigma)
epsNSigma ~ dunif(0,10)
epsNTau <- 1/(epsNSigma * epsNSigma)

for (i in 1:5){
  beta[i] ~ dnorm(0,0.001)
  }
for (i in 1:5){
  betaN[i] ~ dnorm(0,0.001)
  }
for (i in 1:nsites){
  alpha[i] ~ dnorm(0,etaTau)
  alphaN[i] ~ dnorm(0,bTau)
  }
for (j in 1:ndates){
  eps[j] ~ dnorm(0, epsTau)
  epsN[j] ~ dnorm(0, epsNTau)
  }

for (i in 1:nm){
  logit(p[i]) <- etaMean + beta[1]*Drn2[i] + beta[2]*Drn3[i] + beta[3]*Trt[i] + beta[4]*Loc[i] + beta[5]*TrtLoc[i] + alpha[site[i]] + eps[date[i]]
  pi[i, 1] <- p[i]
  pi[i, 2] <- p[i] * (1 - p[i])
  pi[i, 3] <- p[i] * (1 - p[i]) * (1 - p[i])
  pi0[i] <- 1-pi[i, 1] - pi[i, 2] - pi[i, 3]
  pcap[i] <- 1 - pi0[i]	#proportion of N captured
  
  for(k in 1:3){
    muc[i, k] <- pi[i, k] / pcap[i]
    }

  #Conditional multinomial
  y[i, 1:3] ~ dmulti(muc[i, 1:3], ncap[i])

  #Observed count of uniques
  ncap[i] ~ dbin(pcap[i], N[i])

  #Abundance model
  N[i] ~ dpois(lambda[i])
  log(lambda[i]) <- b + betaN[1] * Drn2[i] + betaN[2] * Drn3[i] + betaN[3] * Trt[i] + betaN[4] * Loc[i] + betaN[5] * TrtLoc[i] + alphaN[site[i]] + epsN[date[i]]
  }
}

model{
for(j in 1:k){ # j is pass and k in number of passes x is number caught n is pop
  x[j] ~ dbin(q[j], n[j])
  n[j+1] <– n[j] – x[j]
  q[j] <– mu * (eta / (eta + j-1))
  }

n[1] <– exp(u)
u ~ dunif(0, 10)
eta <- exp(log.eta)
log.eta ~ dunif(0, 10)
#log.eta < –10 # needed only when restricting M_u to M_e

mu ~ dbeta(1.1, 1.1)
}
```
Simulate population removal

```{r sim_removal}
# data
M <- 20000 # super population size
S <- 50 # number of sites
J <- 3 # number of removals

#ncap <- 500 # total number of individuals captured

# parameters
#alpha_s <- rep(1/(S), S) # multinomial intercept
b0_p <- 0.5 # intercept for p
sigma_p_M <- 0.5 # individual variation in p
sigma_p_S <- 0.1 # site to site variation in p

b0_lam <- log(200) # log of Poisson expectation. Should be smaller than M / S
sigma_lam_S <- 0.25 # site to site variation in lambda

sigma_p_I <- 0.25 
sigma_p_S <- 0.10

# transformed parameters
#alpha_s <- c(-1.0 * sum(alpha_raw_s), alpha_raw_s) # sum to zero constraint

## Initialize containers
group <- matrix(NA, M, S) # site
p <- matrix(NA, M, S) # capture probability
pi <- array(NA, dim = c(M, S, J+1)) # removal parameter
lambda <- rep(NA, S) # expectation for abundance
probs <- rep(NA, S) # site membership probs
z <- rep(NA, M) # availability
pz <- matrix(NA, M, S) # p * z

# abundance model for each site
for(s in 1:S){
  lambda[s] <- exp(b0_lam + rnorm(1, 0, sigma_lam_S))
  }
# probabilities for site membership
for(s in 1:S){
  probs[s] <- lambda[s] / sum(lambda)
  }

# DERIVED parmaeter psi
psi <- sum(lambda) / M

# Model for individual encounters
for(i in 1:M){
  group[i, ] <- rmultinom(1, 1, probs)
  z[i] <- rbinom(1, 1, psi)
  }

site <- apply(group, 1, function(x) which(x == 1)) * z # site index
site <- site[which(site != 0)] # site index
y <- tibble(site = site, cap1 = 0, cap2 = 0, cap3 = 0, cap0 = 0) %>%
  arrange(site) %>%
  mutate(indiv = 1:length(site), .before = site)

# observation model
for(i in 1:dim(y)[1]){
  for(s in 1:S){
    p[i, s] <- plogis(b0_p + rnorm(1, 0, sigma_p_I) + rnorm(1, 0, sigma_p_S))
    pi[i, s, 1] <- p[i, s]
    pi[i, s, 2] <- p[i, s] * (1 - p[i, s])
    pi[i, s, 3] <- p[i, s] * (1 - p[i, s])^2
    pi[i, s, 4] <- (1 - p[i, s])^3 # prob of not being captured
    
    y[i, s, 1:4] <- as.vector(rmultinom(1, 1, pi[i, s, ]))
    }
 }

```




```{r model}
# data
M <- 20000 # super population size
S <- 50 # number of sites
J <- 3 # number of removals
L <- rnorm(M, 0, 1) # simulate (scaled and centered) fish lengths

# ncap <- 500 # total number of individuals captured

# parameters
# alpha_s <- rep(1/(S), S) # multinomial intercept
a0_p <- 0.5 # intercept for p
b1_p <- 1 # coefficent for length effect on p
sigma_p_M <- 0.5 # individual variation in p
sigma_p_S <- 0.1 # site to site variation in p

a0_lam <- log(200) # log of Poisson expectation. Should be smaller than M / S
sigma_lam_S <- 0.25 # site to site variation in lambda

sigma_p_I <- 0.25 
sigma_p_S <- 0.10

# transformed parameters
# alpha_s <- c(-1.0 * sum(alpha_raw_s), alpha_raw_s) # sum to zero constraint

## Initialize containers
lambda <- rep(NA, S) # expectation for abundance
cat_probs <- rep(NA, S) # site membership probs
site <- matrix(NA, M, S) # site
p <- rep(NA, M) # capture probability
pi <- matrix(NA, M, J+1) # removal probability
z <- rep(NA, M) # availability for capture
pz <- matrix(NA, M, S) # p * z
y <- matrix(NA, M, J+1) # observation matrix

# Simulate non-centered group effects
#for(s in 1:S){
##  gamma_p_S[s] <- rnorm(1, 0, sigma_p_S) # site effects on p
#  gamma_lam_S[s] rnorm(1, 0, sigma_lam_S) # site effects on lambda
#  }

# abundance model for each site
for(s in 1:S){
  lambda[s] <- exp(a0_lam + rnorm(1, 0, sigma_lam_S))
  }
# probabilities for site membership
for(s in 1:S){
  cat_probs[s] <- lambda[s] / sum(lambda)
  }

# DERIVED parmaeter psi for probability of encounter
psi <- sum(lambda) / M

# Model for individual encounters
for(i in 1:M){
  site[i, ] <- rmultinom(1, 1, cat_probs)
  z[i] <- rbinom(1, 1, psi)

# observation model
  p[i] <- plogis(a0_p + b1_p * L[i] + rnorm(1, 0, sigma_p_I) + rnorm(1, 0, sigma_p_S))
  for(j in 1:J+1){
    pi[i, 1] <- p[i]
    pi[i, 2] <- p[i] * (1 - p[i])
    pi[i, 3] <- p[i] * (1 - p[i])^2
    pi[i, 4] <- (1 - p[i])^3
    
    y[i, ] <- as.vector(rmultinom(1, 1, pi[i, ]))
    }
 }

data <- as.tibble(indiv = seq(1, M, 1),
                  site = site, 
                  r1 = y[, 1], 
                  r2 = y[, 2], 
                  r3 = y[, 3], 
                  r0 = y[, 4])
```



```{r model}
## Data ##

M <- 20000 # super population size
S <- 30 # number of sites
J <- 3 # number of removals
L <- rnorm(M, 0, 1) # simulate (scaled and centered) fish lengths

## Parameters ##

a0_p <- 0.5 # intercept for p
b1_p <- 1 # coefficent for length effect on p
sigma_p_S <- 0.1 # site to site variation in p
a0_lam <- log(200) # log of Poisson expectation. Should be much smaller than M / S
sigma_lam_S <- 0.5 # site to site variation in lambda


## Transformed Parameters ##

lambda <- rep(NA, S) # expectation for abundance
cat_probs <- rep(NA, S) # site membership probs
site <- matrix(NA, M, S) # site matrix
site_index <- rep(NA, M) # integer index 1:S for i in 1:M
p <- rep(NA, M) # capture probability
pi <- matrix(NA, M, J+1) # removal probability
z <- rep(NA, M) # availability for capture
pz <- matrix(NA, M, S) # p * z
y <- matrix(NA, M, J+1) # observation matrix
gamma_p_S <- rep(NA, S) # random site effects on p
gamma_lam_S <- rep(NA, S) # random site effects on lambda

for(s in 1:S){ # Simulate non-centered site effects
  gamma_p_S[s] <- rnorm(1, 0, sigma_p_S) # site effects on p
  gamma_lam_S[s] <- rnorm(1, 0, sigma_lam_S) # site effects on lambda
}

## Likelihood ##

for(s in 1:S){ # abundance model for each site
  lambda[s] <- exp(a0_lam + gamma_lam_S[s])
  }

for(s in 1:S){ # multinomial probabilities of site membership in superpopulation
  cat_probs[s] <- lambda[s] / sum(lambda)
  }

psi <- sum(lambda) / M # DERIVED parameter for probability of encounter

# Model for individual encounters
for(i in 1:M){
  site[i, ] <- rmultinom(1, 1, cat_probs)
  site_index[i] <- which(site[i, ] == 1) #apply(site, 1, function(x) which(x == 1)) 
  
  z[i] <- rbinom(1, 1, psi) # encountered or available for capture
  
  p[i] <- plogis(a0_p + b1_p * L[i] + gamma_p_S[s])
  
  pi[i, 1] <- p[i]
  pi[i, 2] <- p[i] * (1 - p[i])
  pi[i, 3] <- p[i] * (1 - p[i])^2
  pi[i, 4] <- (1 - p[i])^3
  y[i, ] <- as.vector(rmultinom(1, 1, pi[i, ]))
  }

data_full <- data.frame(indiv = seq(1, M, 1),
                        avail = z,
                        site = site_index, 
                        length = L,
                        r1 = y[, 1], 
                        r2 = y[, 2], 
                        r3 = y[, 3], 
                        r0 = y[, 4])

data <- data_full[which(data_full$avail == 1 & data_full$r0 == 0),] %>%
  as_tibble() %>%
  arrange(site) %>%
  select(site,
         length,
         r1,
         r2,
         r3)
```


```{r model}
## Data ##
S <- 20 # number of sites
J <- 3 # number of removals
ncap <- sample(100:300, S) # total number captured at each site
L <- rnorm(sum(ncap), 0, 1) # simulate (scaled and centered) fish lengths
nind <- sum(ncap) # total number captured across all sites

## Parameters ##
a0_p <- 0.5 # intercept for p
b1_p <- 0.1 # coefficent for length effect on p
sigma_p <- 0.1 # site to site variation in p
a0_lam <- log(200) # log of expectation for abundance.
sigma_lam <- 0.5 # site to site variation in lambda


## Transformed Parameters ##
site <- rep(1:S, times = ncap)
p <- rep(NA, nind) 
pi <- matrix(NA, nind, J)
pi0 <- rep(NA, nind)
pcap <- rep(NA, nind)
muc <- matrix(NA, nind, J)
N_i <- rep(NA, nind) 
y <- matrix(NA, nind, J) 
gamma_p <- rep(NA, S) 

## Likelihood ##
for(s in 1:S){ 
  # non-centered random site effects
  gamma_p[s] <- rnorm(1, 0, sigma_p) # effects on p
  
  # Model for N
  #N[s] <- rnbinom(1, size = ncap[s], mu = ncap[s] / p)
  }

# Model for individual encounters
for(i in 1:nind){
  p[i] <- plogis(a0_p + b1_p * L[i] + gamma_p[site[i]])
  
  pi[i, 1] <- p[i]
  pi[i, 2] <- p[i] * (1 - p[i])
  pi[i, 3] <- p[i] * (1 - p[i])^2
  pi0[i] <- (1 - p[i])^3 # prob not captured across all removals
  pcap[i] <- 1 - pi0[i] # prob captured across all removals
  muc[i, ] <- pi[i, ] / pcap[i] # multinomial probs for y|Nc
  
  y[i, ] <- as.vector(rmultinom(1, 1, muc[i, ]))
  
  # Derived parameter N_i = y + (n-y)
  N_i[i] <- 1 + rnbinom(1, size = 1, prob = pcap[i]) # N (is N not N_i + ncap?)
  }

# Derived parameter N_hat
N_hat <- sum(N_i)

data_full <- data.frame(indiv = seq(1, nind, 1),
                        site = site, 
                        length = L,
                        r1 = y[, 1], 
                        r2 = y[, 2], 
                        r3 = y[, 3])

data <- data_full %>%
  as_tibble() %>%
  arrange(site) %>%
  select(site,
         length,
         r1,
         r2,
         r3)

data1 <- list(y = y,
              L = L,
              #ncap = ncap,
              nind = dim(y)[[1]],
              nsite = length(ncap),
              nrem = dim(y)[[2]], 
              site = rep(1:S, times = ncap)
              )
```


```{stan mocc_model_1, eval=FALSE, include=TRUE, output.var='mod1'}
data {
  int<lower = 1> nind; // number of individuals captured (across all site)
  int<lower = 1> nrem; // number of removals
  int<lower = 1> nsite; // number of sites
  int<lower = 1> site [nind]; // indicator for s in s=1,..., S sites
  real L[nind]; // length covariate
  array[nind, nrem] int <lower = 0, upper = 1>  y; // removal capture history
}

parameters {
  real a0_p;
  real b1_p;
  real<lower = 0> sigma_p; // scale of site to site variation in p
  vector[nsite] z_p; // non-centered site effects
}

transformed parameters {
  vector [nind] log_lik;
  real<lower = 0, upper = 1> p[nind];
  vector [nsite] g_p;
  vector[nrem] pie[nind];
  simplex[nrem] muc[nind];
  vector[nind] pi0;
  vector[nind] pcap;
  
  // ranefs for p
  for(s in 1:nsite){
    g_p[s] = z_p[s] * sigma_p;
    }

  for(i in 1:nind) {
    p[i] = inv_logit(a0_p + b1_p * L[i] + g_p[site[i]]); 

    pie[i, 1] = p[i]; // probability of removal on pass 1
    pie[i, 2] = p[i] * (1-p[i]); // pass 2
    pie[i, 3] = p[i] * (1 - p[i]) ^ 2; // pass 3
  
    pi0[i] = (1 - p[i])^3; // prob not captured across all removals
    pcap[i] = 1 - pi0[i]; // prob captured across all removals
    muc[i, ] = pie[i, ] / pcap[i]; // multinomial probs for y|ncap

    log_lik[i] = multinomial_lpmf(y[i, ] | muc[i, ]);
    }
}

model {
  // priors
  target += normal_lpdf(a0_p | 0, 5);
  target += normal_lpdf(b1_p | 0, 2.5);
  target += normal_lpdf(sigma_p | 0, 2.5);
  target += normal_lpdf(z_p | 0, 1);
  
  // sum log-likelihood
  target += sum(log_lik);
}

generated quantities {
  int <lower = 0> N_i[nind];
  int <lower = 0> N_s[nsite];
  int <lower = 0> N;
  
  for(i in 1:nind){
    N_i[i] = 1 + neg_binomial_rng(1 * (1 - pcap[i]), pcap[i]);
    for (s in 1:nsite){
      N_s[s] = sum(N_i[site[i] == s]);
      }
    }
  
  N = sum(N_i);
}
```


### Fit
Fit the model via $rstan$ interface to $Stan$
```{r fit_mod1, eval=FALSE, include=TRUE}

fit1 <- sampling(
  object = mod1,
  data = data1,
  chains = 4,
  iter = 1000,
  cores = 4,
  thin = 1,
  seed = 1357#,
  #control = list(adapt_delta = 0.95, max_treedepth = 14)
  )

#save(fit1, file = "C:/Users/rmartin/OneDrive - Environmental Protection Agency (EPA)/Documents/eDNA_RARE/model_files/fit1.rda")
```

### Parameters summary
Tabular summary of parameters in the linear predictors.
```{r print_mod1, echo=TRUE}
#load("C:/Users/rmartin/OneDrive - Environmental Protection Agency (EPA)/Documents/eDNA_RARE/model_files/fit1.rda")

print(fit1, pars = c("a0_p",  "b1_p", "sigma_p", "N", "lp__"), digits_summary = 2)
```







